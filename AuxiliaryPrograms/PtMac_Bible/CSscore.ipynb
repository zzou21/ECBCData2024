{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-size: 14pt;\"><b>Intermediate Training and Fine-tuning of BERT on Geneva Bible</b></span><br><br>\n",
    "<span style=\"font-family: Arial; font-size: 12pt;\">Author: Lucas Ma</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first chunk of code loads the pretrained model in the repo. Note: the directory of the trained model is purposefully untracked by git. Please do not attempt to track it by \"git add XXX\" as it prevents you from pushing successfully to the remote main branch i.e. our GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# Load the fine-tuned MacBERTh model and tokenizer\n",
    "# model_name = './fine-tuned-MacBERTh'  # Path to your fine-tuned model\n",
    "model_name = \"emanjavacas/MacBERTh\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word, tokenizer, model):\n",
    "    # Tokenize the input word\n",
    "    inputs = tokenizer(word, return_tensors='pt')\n",
    "    \n",
    "    # Get the hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # Extract the last hidden state for the input token\n",
    "    hidden_states = outputs.hidden_states[-1]  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "    \n",
    "    # Get the embedding for the first token (the input word)\n",
    "    word_embedding = hidden_states[0, 1, :]  # Assuming the word is at position 1\n",
    "    return word_embedding\n",
    "\n",
    "# Example words\n",
    "word1 = \"Virginia\"\n",
    "word2 = \"sathan\"\n",
    "\n",
    "# Get embeddings for the words\n",
    "embedding1 = get_word_embedding(word1, tokenizer, model)\n",
    "embedding2 = get_word_embedding(word2, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'Virginia' and 'sathan': 0.9525505900382996\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    # Ensure the embeddings are normalized\n",
    "    embedding1 = F.normalize(embedding1, p=2, dim=0)\n",
    "    embedding2 = F.normalize(embedding2, p=2, dim=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = torch.dot(embedding1, embedding2).item()\n",
    "    return cosine_sim\n",
    "\n",
    "# Compute the cosine similarity between the embeddings\n",
    "cosine_sim = cosine_similarity(embedding1, embedding2)\n",
    "print(f\"Cosine Similarity between '{word1}' and '{word2}': {cosine_sim}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

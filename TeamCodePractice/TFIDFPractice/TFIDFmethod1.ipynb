{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF practice. Method 1: relying mostly on TfidfVectorizer without pandas\n",
    "\n",
    "This practice file uses the \"EEBOphase2_1590-1639_body_texts\" folder from DCC.\n",
    "\n",
    "Helpful tutorial: https://www.youtube.com/watch?v=i74DVqMsRWY\n",
    "\n",
    "Helpful note: \"the function get_feature_namest() for the vectorizer is now deprecated; when version 1.2 of sklearn is released the function will be completely removed (thus breaking the code in this video). The new standard function to use is to change the line to: vectorizer.get_feature_names_out().\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUSE THIS CODE IF YOU WISH TO STORE THE CONTENT OF FILES IN A JSON:\\n\\nwith open(\"file.json\", \"w\", encoding=\"utf-8\") as jsonDestination:\\n    json.dump(titleContentDictionary, jsonDestination, indent=4)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the folder pathname here:\n",
    "folderPath = \"/Users/Jerry/Desktop/Submission Diary entries\"\n",
    "\n",
    "# The following dictionary stores the content of all files. The document is in this format - key: (type: string. file name without \".txt\") | value: (type: string. the text of the document combined into one paragraph):\n",
    "\n",
    "titleContentDictionary = {}\n",
    "\n",
    "# The loadFolder function below reads the \"folderPath\" variable and loads content into the dictionary above.\n",
    "def loadFolder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filePath = os.path.join(folder, filename)\n",
    "            with open(filePath, \"r\") as fileToOpen:\n",
    "                content = fileToOpen.read()\n",
    "                content = content.replace(\"\\n\", \"\")\n",
    "                content = \" \".join(content.split())\n",
    "                titleContentDictionary[filename[:-4]] = content\n",
    "loadFolder(folderPath)\n",
    "\n",
    "#FOR DEBUG: print(titleContentDictionary[\"A00002\"])\n",
    "\n",
    "'''\n",
    "USE THIS CODE IF YOU WISH TO STORE THE CONTENT OF FILES IN A JSON:\n",
    "\n",
    "with open(\"file.json\", \"w\", encoding=\"utf-8\") as jsonDestination:\n",
    "    json.dump(titleContentDictionary, jsonDestination, indent=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to clean stopwords and punctuation marks. Call this function if needed\n",
    "def cleanStopwordsPunctuation(content):\n",
    "    splittedContent = content.split()\n",
    "    withStopwordsRemovedList = []\n",
    "    for word in splittedContent:\n",
    "        if word not in stopwords.words(\"english\"):\n",
    "            withStopwordsRemovedList.append(word)\n",
    "    withStopwordsRemovedString = \" \".join(withStopwordsRemovedList)\n",
    "    punctuationRemoved = withStopwordsRemovedString.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    return(punctuationRemoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    max_features = 100, # an integer. This decides how many output terms from most frequent to least frequent you wish the program to provide. For example, max_features = 100 means you wish to see the 100 most frequent terms (ngrams) in the corpus.\n",
    "    max_df = 0.8, # a float. Words appearing in over 80% of documents will be ignored.\n",
    "    min_df = 5, # an integer. Words appearing in less than 5 documents will be ignored.\n",
    "    ngram_range = (1,3), # looking at single word, double-word-group (bigram), and triple-word-group (trigram). From 1 to 3-term pairs. Could change the number to customize the size of the terms you wish to see. E.g.: (2, 3) would mean only searching for bigrams and trigrams.\n",
    "    stop_words = \"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# This variable grabs only the values (or the file content) from the \"titleContentDictionary\" dictionary, since vectorizer only takes in content and not file name. \n",
    "contentAsDictValues = titleContentDictionary.values() # Type: <class \"dict_values\"> . This is NOT a list and should not be passed into \"vectorizer.fit_transform\" in the next cell!\n",
    "\n",
    "# This variable stores the content of the files and should be passed into \"vectorizer.fit_transform\" in the next file.\n",
    "contentAsList = []\n",
    "\n",
    "# This \"for\" loop is to turn the <class \"dict_values\"> variable \"contentAsDictValues\" into the <class \"list> variable \"contentAsList\"\n",
    "for chapter in titleContentDictionary.values():\n",
    "    contentAsList.append(chapter)\n",
    "#FOR DEBUG: print(type(contentAsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'led', 'menu', 'distance', 'said', 'present', 'reading', 'year old', 'described', 'covered', 'vote', 'law', 'finished', 'written', 'social', 'lips', 'lot', 'violent', 'considered', 'light', 'shot', 'bad', 'trouble', 'violence', 'sofa', 'media', 'coffee', 'felt', 'water', 'guess', 'respect', 'en route', 'door', 'things', 'glad', 'thousand', 'problem', 'information', 'wing', 'department', 'struck', 'moved', 'eye', 'old man', 'party', 'mayi', 'lost', 'ben abbes', 'powerful', 'sky', 'question', 'muslim brotherhood', 'want', 'ago', 'tone', 'enjoyed', 'man', 'let', 'months', 'marie', 'impossible', 'local', 'bottle', 'strange', 'opened', 'morning', 'lived', 'cold', 'expressed', 'come', 'socialists', 'did', 'dressed', 'close', 'experience', 'aside', 'ready', 'personal', 'failure', 'circumstances', 'smooth', 'devoted', 'face', 'open', 'sorbonne', 'met', 'win', 'pure', 'moment', 'hotel', 'leave', 'yes', 'idea', 'slowly', 'elegant', 'la', 'shopping', 'living room', 'rate', 'france', 'paper', 'turning', 'june', 'thirty', 'wondered', 'visit', 'don think', 'feeling', 'answer', 'des', 'subject', 'broke', 'national', 'women', 'park', 'mosque', 'mention', 'war', 'food', 'youth', 'eventually', 'white', 'courage', 'hello', 'hands', 'bodies', 'famous', 'cigarette', 'doing', 'fell', 'nativist', 'route', 'sudden', 'll', 'worked', 'married', 'neighbourhood', 'carried', 'supposed', 'cheese', 'equally', 'slow', 'reception', 'beauty', 'chinese', 'read', 'allowed', 'standing', 'likely', 'plus', 'admit', 'jesus', 'sad', 'half hour', 'giving', 'mohammed ben', 'eu', 'forgotten', 'quick', 'spend', 'far right', 'saying', 'metal', 'sense', 'en', 'intense', 'room', 'hall', 'happened', 'doors', 'hours', 'stopped', 'extreme', 'hung', 'right', 'abbes', 'hit', 'spent', 'woke', 'original', 'occurred', 'seen', 'usually', 'eyes', 'begun', 'look', 'body', 'company', 'expected', 'attractive', 'avoid', 'second', 'spent years', 'change', 'certain', 'greeted', 'planned', 'helped', 'hope', 'return', 'trying', 'mainly', 'number', 'pages', 'sat', 'play', 'sight', 'questions', 'hardly', 'new', 'promised', 'amazing', 'education', 'named', 'good', 'worried', 'sign', 'inspired', 'set', 'lives', 'leaving', 'myriam', 'bed', 'true', 'general', 'government', 'work', 'fifth', 'plan', 'contrast', 'english', 'job', 'playing', 'secret', 'meet', 'le', 'death', 'talk', 'faced', 'base', 'dream', 'turn', 'life', 'certainly', 'rare', 'arms', 'meant', 'mohammed', 'dealing', 'floor', 'don', 'husband', 'state', 'situation', 'table', 'drove', 'ligugé', 'unlike', 'served', 'try', 'socialist', 'muslims', 'university', 'le pen', 'silence', 'candidate', 'big', 'presence', 'brought', 'perfect', 'lay', 'drink', 'simple', 'history', 'brandy', 'place', 'aren', 'taking', 'hear', 'couldn', 'better', 'self', 'settled', 'nineteenth', 'looking', 'wore', 'worry', 'ordered', 'clearly', 'shook head', 'preface', 'promise', 'regime', 'les', 'gazed', 'getting', 'rue', 'grow', 'christ', 'windows', 'really', 'excellent', 'universal', 'zola', 'north', 'invited', 'ended', 'tradition', 'speech', 'foreign', 'civil', 'left', 'surprised', 'results', 'sooner later', 'islam', 'basically', 'surprise', 'brussels', 'lots', 'birth', 'cent', 'tv', 'day', 'edge', 'hour', 'campaign', 'train', 'pleasures', 'metres', 'kept', 'movement', 'simply', 'tanneur', 'laid', 'woman', 'metro', 'access', 'offices', 'status', 'marie françoise', 'market', 'taste', 'isn', 'easy', 'garden', 'rediger', 'union', 'lit', 'christian', 'outside', 'reread', 'know', 'school', 'talked', 'power', 'satisfaction', 'clothes', 'shook', 'lead', 'taken', 'university paris', 'happen', 'conversation', 'having', 'offer', 'accepted', 'parents', 'actually', 'news', 'home', 'small', 'economy', 'wait', 'public', 'start', 'blow', 'reasons', 'father', 'understand', 'bar', 'writing', 'desire', 'looked like', 'remained', 'watched', 'person', 'days', 'completely', 'changes', 'convert', 'saudi', 'despite', 'easily', 'remarkable', 'intelligence', 'walking', 'dress', 'began', 'spending', 'weeks', 'stood', 'reached', 'minister', 'tiny', 'notice', 'settle', 'colleague', 'noticed', 'friendly', 'françois', 'sadness', 'intellectual', 'universe', 'round', 'closer', 'centre', 'phrase', 'quickly', 'polls', 'pen', 'slipped', 'won', 'filled', 'holding', 'took', 'feel', 'die', 'tried', 'belonged', 'passed', 'support', 'stepped', 'city', 'smiled', 'plenty', 'choice', 'vast', 'paid', 'changed', 'entire', 'field', 'soft', 'higher', 'touched', 'liked', 'men', 'cut', 'house', 'pension', 'reason', 'spread', 'entirely', 'informed', 'professional', 'muslim', 'states', 'main', 'dead', 'principle', 'avenue', 'quite', 'silent', 'discussing', 'corner', 'waiting', 'age', 'large', 'carnal', 'month', 'given', 'point', 'wearing', 'showed', 'appeared', 'absolutely', 'far', 'friends', 'words', 'enthusiasm', 'sound', 'surprising', 'chance', 'gave', 'order', 'islamic', 'administration', 'important', 'later', 'prime', 'division', 'et', 'near', 'mistake', 'form', 'jeans', 'degree', 'generally', 'suffering', 'countries', 'window', 'instead', 'mean', 'student', 'paris', 'going', 'necessary', 'broad', 'reader', 'imagined', 'able', 'exhausted', 'teach', 'entrance', 'family', 'exactly', 'deep', 'voice', 'private', 'got', 'ideas', 'world', 'years', 'knew', 'course', 'ordinary', 'single', 'position', 'huysmans', 'comes', 'difficult', 'short', 'run', 'restaurant', 'common', 'relations', 'walk', 'memory', 'online', 'fighting', 'minutes later', 'needed', 'article', 'country', 'literary', 'away', 'atmosphere', 'robert', 'slightly', 'debate', 'meals', 'empire', 'writers', 'lined', 'music', 'brotherhood', 'hold', 'managed', 'mouth', 'french', 'sunday', 'probably', 'use', 'nowadays', 'extremely', 'bit', 'ran', 'existence', 'finally', 'jacket', 'child', 'bourgeois', 'hair', 'europe', 'wine', 'wouldn', 'relationship', 'dissertation', 'night', 'firm', 'basic', 'seriously', 'realised', 'calm', 'mind', 'beginning', 'remembered', 'girls', 'parties', 'maintain', 'truth', 'middle', 'head', 'building', 'book', 'nearly', 'books', 'meeting', 'added', 'author', 'arab', 'told', 'stand', 'special', 'catch', 'red', 'club', 'explained', 'apartment', 'early', 'fucking', 'future', 'according', 'free', 'claimed', 'authority', 'evening', 'offered', 'historic', 'speaking', 'maybe', 'speak', 'young', 'replaced', 'european', 'complete', 'didn know', 'images', 'didn think', 'think', 'week', 'jean', 'love', 'low', 'slightest', 'working', 'attacked', 'internet', 'fight', 'mother', 'worse', 'christianity', 'poured', 'past', 'model', 'girl', 'heart', 'various', 'teaching', 'black', 'monsieur', 'minutes', 'disappear', 'religion', 'buy', 'pleasure', 'seven', 'today', 'sure', 'literature', 'saint', 'contact', 'elections', 'aware', 'sorry', 'sounds', 'direct', 'understood', 'deserted', 'gone', 'late', 'practically', 'dark', 'chose', 'hôtel', 'street', 'hard', 'works', 'kind', 'beer', 'fucked', 'normal', 'children', 'period', 'talking', 'gradually', 'fallen', 'fact', 'ben', 'saw', 'real', 'universities', 'stay', 'guests', 'political', 'car', 'step', 'grey', 'couple', 'called', 'election', 'spirit', 'students', 'peace', 'clear', 'attention', 'journal', 'arguments', 'page', 'thanks', 'wasn really', 'hand', 'thinking', 'stop', 'letter', 'looks', 'democracy', 'closed', 'colleagues', 'agreed', 'died', 'continued', 'centuries', 'century', 'started', 'art', 'year', 'caught', 'loved', 'longer', 'numbers', 'glance', 'fuck', 'usual', 'making', 'human', 'make', 'email', 'strength', 'individual', 'old', 'live', 'mobile', 'looked', 'badly', 'bottles', 'end', 'bring', 'south', 'pretty', 'fair', 'recognised', 'best', 'values', 'president', 'hadn', 'spiritual', 'soon', 'wrong', 'maintained', 'thing', 'example', 'grew', 'pass', 'nineteenth century', 'years later', 'seeing', 'starting', 'classes', 'civilisation', 'buildings', 'wives', 'pundits', 'answered', 'inside', 'coat', 'walked', 'watch', 'western', 'including', 'published', 'long', 'rest', 'years ago', 'sexual', 'case', 'beautiful', 'sitting', 'major', 'afraid', 'particular', 'convinced', 'opposite', 'security', 'republic', 'held', 've', 'teachers', 'master', 'sort', 'female', 'god', 'minor', 'remember', 'believe', 'interesting', 'events', 'people', 'argue', 'reach', 'chosen', 'honest', 'deal', 'israel', 'hadn seen', 'station', 'used', 'brother', 'steve', 'straight', 'marriage', 'followed', 'service', 'recognise', 'witness', 'theory', 'high', 'huge', 'blue', 'brief', 'professor', 'known', 'bedroom', 'reduced', 'especially', 'doubt', 'little little', 'society', 'negotiations', 'wanted', 'growing', 'half', 'share', 'doctoral', 'roman', 'class', 'coming', 'heard', 'monastic', 'obviously', 'view', 'catholic', 'say', 'air', 'thought', 'warm', 'asked', 'clock', 'long time', 'level', 'daily', 'odd', 'dinner', 'care', 'terms', 'steps', 'ask', 'happy', 'drunk', 'courtyard', 'fine', 'studies', 'arse', 'agreement', 'church', 'conversion', 'mohammed ben abbes', 'obvious', 'sooner', 'bought', 'help', 'doesn', 'françoise', 'smile', 'impression', 'don know', 'bloy', 'touch', 'speed', 'academic', 'phone', 'ones', 'rising', 'anti', 'suddenly', 'living', 'weren', 'truly', 'group', 'setting', 'imagine', 'decided', 'religious', 'rose', 'connection', 'joined', 'barely', 'importance', 'write', 'raised', 'shirt', 'naturally', 'calling', 'word', 'different', 'interested', 'moving', 'apart', 'civil war', 'fast', 'received', 'sun', 'older', 'effect', 'tell', 'times', 'eat', 'great', 'glass', 'falling', 'immediately', 'groups', 'learned', 'difference', 'wrote', 'came', 'happiness', 'nice', 'possible', 'majority', 'career', 'natural', 'pro', 'iii', 'turned', 'confirmed', 'politics', 'land', 'office', 'account', 'matter', 'afternoon', 'existed'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THESE VARIABLES ARE FOR DEBUG PURPOSES\n",
    "test1 = \"Los Angeles is a city of quartz, reflecting the lights from a sun that no longer melts even the snowflakes falling during an afternoon in June of 2026.\"\n",
    "test2 = \"San Francisco is a city of quartz, reflecting the lights from a sun that no longer melts even the snowflakes falling during an afternoon in June of 2026.\"\n",
    "test3 = \"Detroit is a city of diamonts, reflecting the lights from a moon that no longer melts ice in June of 2025.\"\n",
    "test4 = \"Detroit is a city of diamonts, reflecting the lights from a moon that no longer melts ice in June of 2025.\"\n",
    "'''\n",
    "\n",
    "'''\n",
    "USE THIS CODE IF YOU ARE STORING YOUR CONTENT IN A JSON RATHER THAN A DICTIONARY\n",
    "jsonAsList = []\n",
    "\n",
    "with open(\"/Users/Jerry/Desktop/Submission Diary entries\", \"r\") as file:\n",
    "    stories = json.load(file)\n",
    "    for story in stories.values():\n",
    "        jsonAsList.append(story)\n",
    "'''\n",
    "\n",
    "vectors = vectorizer.fit_transform(contentAsList)\n",
    "featuresNames = vectorizer.get_feature_names_out() #no parameters passed in.\n",
    "dense = vectors.todense()\n",
    "denseList = dense.tolist()\n",
    "\n",
    "#this list will be a list of lists --- i.e.: [[content, content], [content, content], [content, content]] that stores the words deemed as significant by the TF-IDF calculation.\n",
    "allKeywords = []\n",
    "'''to interpret the \"allKeywords\" list of lists: the index number of one list is the same as the index number of the file content in the \"contentAsList\" list. For example, allKeywords[0] calls the first list in the \"allKeywords\" list of lists. The words in allKeywords[0] are the significant words from the file content stored in contentAsList[0].\n",
    "'''\n",
    "\n",
    "for term in denseList:\n",
    "    x = 0\n",
    "    keywords = []\n",
    "    for word in term:\n",
    "        if word > 0:\n",
    "            keywords.append(featuresNames[x])\n",
    "        x += 1\n",
    "    allKeywords.append(keywords)\n",
    "\n",
    "# This \"for\" loop will print out the signifciant words\n",
    "for list in allKeywords:\n",
    "    print(list)\n",
    "\n",
    "'''\n",
    "THIS CODE WILL PRINT OUT ALL UNIQUE WORDS DEEMED AS SGINIFICANT FROM THE ENTIRE FOLDER.\n",
    "\n",
    "allKeywordsver2Set = set()\n",
    "for list in allKeywords:\n",
    "    temporarySet = set()\n",
    "    for word in list:\n",
    "        temporarySet.add(word)\n",
    "    for word in temporarySet:\n",
    "        allKeywordsver2Set.add(word)\n",
    "print(allKeywordsver2Set)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

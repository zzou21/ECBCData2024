---
title: "Clustering of Projection Results" 
author: "Lucas Ma"
---

To begin, load relevant packages to be used for analysis.

```{r}
library(dplyr)
library(cluster)
library(tidyverse)
library(factoextra)
```

First, perform initial data cleaning. The below df_va dataframe is one that has removed all unnecessary original formatting as well as texts in which the term "Virginia" does not directly or indirectly appear.

```{r, eval=FALSE}
# This chunk of code is obsolete as it attempts to clean the .txt file. Now as we have the cleaned .csv file, thanks to Jerry, this chunk is no longer useful.

# Load the text file as a data frame
df <- read.table("projection_result.txt", header = FALSE, sep = "\t", stringsAsFactors = FALSE)

# View the first few rows of the data frame
head(df)

df_split <- df |> 
  separate(V1,into = c("Filename", "Projections"), sep = ": ")

df_split$Projections <- df_split$Projections |>
  str_replace_all("\\[|\\]", "")

head(df_split)

df_cleaned <- df_split |>
  separate(Projections, into = c("P_christ", "P_edu", "P_clothes"), sep = ", ") 

df_va <- df_cleaned |>
  filter(P_christ != "0") |>
  mutate(
    P_christ = as.numeric(P_christ),
    P_edu = as.numeric(P_edu),
    P_clothes = as.numeric(P_clothes)
  )

head(df_va)
```

```{r}

df = read.csv("projectionResultTable.csv")

head(df)

df_va <- df |>
  rename(
    "Filename" = `File.Name`,
    "P1" = `Projection..1`,
    "P2" = `Projection..2`,
    "P3" = `Projection..3`,
    "Title" = `Manuscript.Title`,
    "Year" = `Publication.Year`
  ) |>
  filter(P1 * P2 * P3 != 0)
```

**Attempt 1: K-means Clustering**

```{r}

set.seed(27708) # For reproducibility

# Standardization
df_k <- df_va |>
  mutate(
    P_christ = scale(P1),
    P_edu = scale(P2),
    P_clothes = scale(P3)
  ) |>
  select(Filename, P_christ, P_edu, P_clothes)

# Function to determine the optimal number of clusters using the elbow method
find_optimal_clusters <- function(data) {
  if (is.vector(data)) {
    data <- matrix(data, ncol = 1)
  }
  wss <- (nrow(data) - 1) * sum(apply(data, 2, var))
  for (i in 2:15) {
    wss[i] <- sum(kmeans(data, centers = i)$withinss)
  }
  return(wss)
}

# Determine the number of clusters for P1, P2, and P3
wss_P1 <- find_optimal_clusters(df_k$P_christ)
wss_P2 <- find_optimal_clusters(df_k$P_edu)
wss_P3 <- find_optimal_clusters(df_k$P_clothes)

# Plot the elbow method for each column
par(mfrow = c(1, 3))
plot(1:15, wss_P1, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares", main = "P1")
plot(1:15, wss_P2, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares", main = "P2")
plot(1:15, wss_P3, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares", main = "P3")
par(mfrow = c(1, 1))

# Apply K-means clustering
k <- 3
kmeans_P1 <- kmeans(matrix(df_k$P_christ, ncol = 1), centers = 2, nstart = 25)
kmeans_P2 <- kmeans(matrix(df_k$P_edu, ncol = 1), centers = 4, nstart = 25)
kmeans_P3 <- kmeans(matrix(df_k$P_clothes, ncol = 1), centers = 4, nstart = 25)

# Compute silhouette values
sil <- silhouette(kmeans_P1$cluster, dist(df_va$P1))

# Print silhouette summary
summary(sil)


# Add the cluster assignments to the original data frame
df_clustered_k <- df_k |> 
  mutate(cluster_P1 = kmeans_P1$cluster,
         cluster_P2 = kmeans_P2$cluster,
         cluster_P3 = kmeans_P3$cluster)

head(df_clustered_k)

# Visualize silhouette plot
fviz_silhouette(sil)
```

The following chunk is shared by all types of clustering for generating visualization.

```{r}

clustered <- df_clustered_k

merged_df <- df_va |>
  left_join(clustered, by = "Filename") 

merged_df <- merged_df |>
  mutate(
    cluster_P1 = as.character(cluster_P1),
    cluster_P2 = as.character(cluster_P2),
    cluster_P3 = as.character(cluster_P3)
  ) 

head(merged_df)

# Below is the first projection

merged_df |>
  ggplot(aes(x = P1, color = cluster_P1)) +  
  geom_density() +
  geom_jitter(aes(y = 0), width = 0, height = 0.1, size = 0.5) + 
  theme_minimal() +
  labs(title = "One-Dimensional Scatterplot",
       x = "P_christ",
       y = "") +
  theme(axis.title.y = element_blank(),  
        axis.text.y = element_blank(),   
        axis.ticks.y = element_blank())


# Below is the second projection

merged_df |>
  ggplot(aes(x = P2, color = cluster_P2)) +  
  geom_density() +
  geom_jitter(aes(y = 0), width = 0, height = 0.1, size = 0.5) + 
  theme_minimal() +
  labs(title = "One-Dimensional Scatterplot",
       x = "P_edu",
       y = "") +
  theme(axis.title.y = element_blank(),  
        axis.text.y = element_blank(),   
        axis.ticks.y = element_blank())

# Below is the third projection

merged_df |>
  ggplot(aes(x = P3, color = cluster_P3)) +  
  geom_density() +
  geom_jitter(aes(y = 0), width = 0, height = 0.2, size = 0.5) + 
  theme_minimal() +
  labs(title = "One-Dimensional Scatterplot",
       x = "P_clothes",
       y = "") +
  theme(axis.title.y = element_blank(),  
        axis.text.y = element_blank(),   
        axis.ticks.y = element_blank())

merged_df |>
  select(Author, cluster_P1, cluster_P2, cluster_P3, P1, Year, Filename, P3) |>
  arrange(cluster_P1) |>
  filter(str_detect(Author, "Copland"))

merged_df |>
  filter(P1<=0.241267) |>
  arrange(desc(P1)) |>
  select(Author)
```

**Attempt 2: Hierarchical Clustering**

```{r}
# Load necessary libraries
library(ggplot2)

# Remove the filename column, as we are clustering based on p1
data_for_clustering <- df_va$P1

# Perform hierarchical clustering
# Compute the distance matrix
dist_matrix <- dist(data_for_clustering, method = "euclidean")

# Perform hierarchical clustering using complete linkage
hc <- hclust(dist_matrix, method = "complete")

# Plot the dendrogram
plot(hc, labels = df_va$Filename, main = "Dendrogram", xlab = "Filename", sub = "", cex = 0.8)

```

Apparently, from the visualization, there can only be 2 branches at each level. This is problematic for our analysis because we have yet determine how many clusters we want overall, but this number is almost certainly not as simply as 2.
